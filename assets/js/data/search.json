[ { "title": "Decoding raw i.MX6 NAND flash images", "url": "/posts/imx6-nand-flash/", "categories": "Embedded", "tags": "NAND, Flash, i.MX6, BCH", "date": "2025-10-26 18:21:00 +0100", "snippet": "I was recently working with a PCB featuring an i.MX6 SoC and a raw NAND flash chip. The SoC was running a u-boot and an embedded Linux off of the NAND flash chip. Since the debug port was properly locked, I wanted to take a look at the embedded u-boot and Linux. I decided to desolder and dump the flash chip. This post documents how the i.MX6 stores user data on an external NAND flash and how this user data can be manually extracted while correcting bit errors.NAND Flash MemoryThe NAND flash memory I was working with supported the ONFI specification 1.0. I followed the post by Colin O’Flynn to solder wires to the BGA pads of the NAND flash. I used enameled wires and taped down each row after the other. I only soldered a single VCC and VDD pad, which turned out to be okay. All in all, I soldered the following connections: Pin Type Description VCC 3V power, I only soldered a single pad VDD Ground, I only soldered a single pad IO0 - IO7 8 bit I/O lines CE# Chip Enable (Active Low) RE# Read Enable (Active Low) WE# Write Enable (Active Low) CLE Command Latch Enable ALE Address Latch Enable WP# Write Protect (Active Low) R/B# Busy signal from NAND, Open Drain The R/B# signal requires a dedicated pull-up resistor since it is an open-drain signal. I didn’t solder the protection pin since the NAND flash has an internal pull-down resistor. The resistor unprotects the chip by default.I used the ONFI applet of the Glasgow Interface Explorer to communicate with the NAND flash. It was very impressive to see the ONFI applet work its magic right out of the box. Conveniently, the Glasgow applet directly dumped the flash characteristics contained in the Parameter Page (see chapter 5.4.1 of the ONFI specificaiton).Flash ParametersThe flash memory had the following characteristics: Parameter Value Bytes per page 2048 Spare bytes per page 64 Pages per erase block 64 Number of logical units 1 Number of block ins a logical unit 4096 Number of bits ECC correctability 4 The last parameter defines the required ECC strength. According to the specification, the host or flash controller must be able to identify and correct this many bit errors per 512 byte of user data. In our case, the ECC must be strong enough to identify and correct up to four bit flips per 512 byte of data. The specification does not say what ECC mechanism must be used or how this data should be organized within a flash page.To me, this was unexpected. Literature or Wikipedia mention the spare area to be specific for ECC or manufacturing information. I simply assumed that this ECC information must then go into the spare area since that was its purpose, right? It turned out that at least in my case, there was no logical distinction between the two. According to the flash memory documentation, flash pages are always written or dumped with the full 2112 bytes.The flash memory page has this extra capacity for correction information, but how or where this information is stored within the page is of no interest to the flash memory. It provides this extra data per page as a convenience to the host, which must define its purpose.In my scenario, the i.MX6 was acting as the host or flash controller. It also handled the page as a contiguous region of memory.Dumping the flashThe Glasgow applet worked right out of the box, and I was able to dump the memory successfully. The applet offers you the option of separating the regular area and spare area of the flash pages into separate files. Although this first sounded like a good idea, I later noticed that the flash controller did not make any distinction between the two. It treated the flash page as a contiguous region of 2112 bytes, so dumping them interleaved was the right choice.As Colin described in his blog, I dumped the memory multiple times to work out any potential bit flips by means of majority voting. I expected my soldered enameled wires to introduce quite a bit of noise and transmission errors. And indeed, after dumping the memory twice and comparing the two dumps, I noticed a few bit errors. Compared to the size of the memory, there were only few, but they were present.Since I first assumed these bit errors to have been caused by interference, I pulled more dumps and wrote a little Python script to work out the errors by means of majority voting. However, the bit errors always occurred at the same locations in the dump and had a rather constant probability of occurring. Sometimes, this probability was almost 50/50, so there was no way to determine the proper value of a bit by pulling more dumps. And even if the bit was more likely to flip one way, there was no easy way of knowing if that was the correct value. In summary, it looked like these bit flips were not produced by the solder setup but by actual errors in the NAND flash chip.To better understand the contents of the dump, I ran binwalk across the file. It looked like large portions of the dump were compressed or even encrypted. Under these circumstances, even a single bit error could prevent a successful decoding. I needed to better understand the format of the flash contents and potentially correct bit errors to be able to successfully extract the data.Flash ControllerIn comparison to NOR flash memory, a NAND flash memory requires more intensive care to be working reliably. This is most notably the handling of bad blocks and the transparent application of ECC to detect and correct bit flips in the data. As I was already able to experience while dumping the data from the memory, bit flips do occur during regular operation and need to be handled.In my case, it was the job of the i.MX6 to take care of these tasks. The i.MX6 features a General Purpose Media Interface (GPMI) that operates as a flash controller. The GPMI uses the BCH accelerator of the chip to implement error correcting codes. The following sections of the reference manual are of interest (the manual can be found with a Google search): Chapter 17: 40-Bit Correcting ECC Accelerator (BCH) 17.2.2: Flash Page Layout 17.6.8: Hardware BCH ECC Flash 0 Layout 0 Register 17.6.9: Hardware BCH ECC Flash 0 Layout 1 Register Chapter 8: System Boot 8.5.2.5: Back block handling in ROM 8.5.2.8: Typical NAND Page Organization The flash controller provides a convenient error-free abstraction of the raw flash memory. It does so by multiplexing the user data with additionall error-correcting information and metadata.Flash LayoutThe flash controller supports different flash page layouts depending on the page size and the ECC needs of the flash chip. In general, the complete flash page (regular and spare area) is divided into blocks. In my case, the user data on the page was split into four block of 512 byte. After each data block comes an ECC block that carries the correcting code for the preceding data block. Before the first block comes a block of metadata. This metadata is specific to the i.MX flash controller. In contrast to ECC1 to ECCN, ECC0 also covers the metadata block.The following image shows the general layout of a flash page:The size of the metadata, the size of the blocks, and the applied BCH strength are configurable (see the mentioned registers above). My first assumption was that the configuration of these registers is done statically by u-boot during boot. I poked around in the u-boot code for a little while until I found the relevant sections.u-boot i.MX Flash ConfigurationI was surprised to see that the configuration of the i.MX6 flash controller in u-boot is not done statically in the sense that a fixed static configuration is applied. Instead, the controller is dynamically configured depending on the characteristics of the chip. When booting, u-boot automatically configures the flash controller according to these flash parameters. The flash parameters are read from the flash chip and stored in struct nand_chip. The two most important values are ecc_strength_ds and ecc_step_ds, which are the required ECC strength and the number of bytes after which an ECC is required. As mentioned above, in my case this was 4 bits of ECC correctability per 512 byte of data.The main function responsible for determining the configuration is called mxs_nand_set_geometry. Based on the known characteristics of the flash chip, I concluded that it branches to mxs_nand_legacy_calc_ecc_layout for calculation of the ECC parameters. An extract of mxs_nand_legacy_calc_ecc_layout is shown below:static inline int mxs_nand_legacy_calc_ecc_layout(struct bch_geometry *geo, struct mtd_info *mtd){ &amp;lt;...&amp;gt; /* The default for the length of Galois Field. */ geo-&amp;gt;gf_len = 13; /* The default for chunk size. */ geo-&amp;gt;ecc_chunk0_size = 512; geo-&amp;gt;ecc_chunkn_size = 512; &amp;lt;...&amp;gt; geo-&amp;gt;ecc_chunk_count = mtd-&amp;gt;writesize / geo-&amp;gt;ecc_chunkn_size; /* * Determine the ECC layout with the formula: * ECC bits per chunk = (total page spare data bits) / * (bits per ECC level) / (chunks per page) * where: * total page spare data bits = * (page oob size - meta data size) * (bits per byte) */ geo-&amp;gt;ecc_strength = ((mtd-&amp;gt;oobsize - MXS_NAND_METADATA_SIZE) * 8) / (geo-&amp;gt;gf_len * geo-&amp;gt;ecc_chunk_count); geo-&amp;gt;ecc_strength = min(round_down(geo-&amp;gt;ecc_strength, 2), nand_info-&amp;gt;max_ecc_strength_supported); &amp;lt;...&amp;gt;}The function configures a block size of 512 bytes and Galois Field GF(13) for the BCH codes. The i.MX metadata field is always set to a length of MXS_NAND_METADATA_SIZE = 10 bytes. With a flash page size of $2048 + 64 = 2112$, the code comes to the conclusion that four blocks fit into a page, meaning that geo-&amp;gt;ecc_chunk_count is four.The only remaining unknown is the length of each ECC field. Instead of directly using what is required according to the flash parameters, the function determines which ECC strength is theoretically achievable based on the available space: the configuration stores four blocks of 512 byte in the page, which completely fills the regular page area. Out of the 64 byte of spare area only 54 byte can be used for ECC since we must account for the 10 byte of metadata. Consequently, each of the four blocks can be protected with 13 bytes of ECC.Since we’re using Galois field GF(2^13), each bit of correctability requires 13 bits of redundancy. In this specific case, $13 \\cdot 8 / 13 = 8$ bits of correctability are at maximum possible based on the available space.After calculating the maximum possible ECC strength, the function checks if this strength satisfies the requirements mentioned in the flash parameter page. Here, the calculated correctability of 8 exceeds the requirement of 4 and is accepted by the function. Hence, we have the following parameters for the flash page protection: Parameter Value Block size 512 byte Metadata size 10 byte BCH Galois Field 13 BCH level BCH8 ECC size per block 13 byte If we fully calculate this through, we have $4 \\cdot 512 + 4 \\cdot 13 + 10 = 2110$ bytes required, which means that the two last bytes in the flash page are unused.Flash Dump Data Reconstruction in PythonNow that the flash page layout was known, the last step was to make use of the ECC fields in the flash pages to correct the bit errors in the dump. This basically meant reimplementing the ECC correction algorithm. After doing a bit of testing, I found that the following steps needed to be implemented: Using the BCH ECC to correct bit errors in the blocks of each page. Swapping the bad block marker from address 0x800 back to page address 0x0. Stripping the $4 \\cdot 13$ bytes of ECC and the two spare bytes at the end of the page to retrieve 2048 byte of user data.Bit correction with BCHThis task is a brilliant example of why I love Python as a tooling language: there already exists a neat Python library called python-bchlib that implements the BCH algorithm.The following code snippet performs the ECC correction in place. A bytearray containing a single flash page is passed into the function and modified in place.from bchlib import BCHUSER_PAGE_LEN = 2048PAGE_LEN = USER_PAGE_LEN + 64META_LEN = 10BLOCK_LEN = 512ECC_LEN = 13EMPTY_ECC = b&quot;\\xff&quot; * ECC_LENdef run_page_ecc_in_place(page: bytearray) -&amp;gt; None: if len(page) != PAGE_LEN: raise ValueError( f&quot;Supplied page data does not have required length: {PAGE_LEN}&quot; ) bch = BCH(8, m=13, swap_bits=True) offset = 0 for block_index in range(4): if block_index == 0: block_len = BLOCK_LEN + META_LEN else: block_len = BLOCK_LEN block_w_ecc = page[offset : offset + block_len + ECC_LEN] block_data = block_w_ecc[:block_len] block_ecc = block_w_ecc[block_len:] expected_ecc = bch.encode(block_data) if block_ecc != EMPTY_ECC and block_ecc != expected_ecc: # The correction is done in place bch.correct(block_data, block_ecc) offset += len(block_w_ecc)Bad Block Marker SwappingAfter correcting the bit errors, I noticed that the dump data still contained spurious 0xFF bytes in an otherwise completely empty flash page. These bytes were always located at offset 0x800. Chapter 8.5.2.5 explains that the single byte at this offset is the original bad block marker written there by the flash manufacturer.The motivation for this behavior is also documented in a legacy document by freescale. Due to the interleaved approach of putting the ECC in between the 512 byte data blocks, the bad block marker at offset 0x800 would be located inside the last data block. To avoid this, the flash controller stores the marker in the metadata field which is kept at the beginning of the page. However, when the page is written to the NAND flash, the bad block marker byte is again swapped back to 0x800 to maintain its original position. The data byte contained at offset 0x800 is placed at offset 0x0. The swapping occurs before the ECC for the page blocks is calculated.We must invert this operation when we manually decode the page. Since, during a write, the ECC is applied after the swap, we must first correct the ECC and then swap back.BB_MARKER_OFFSET = 0x800def swap_bb_marker_in_place(page: bytearray) -&amp;gt; None: tmp = page[0] page[0] = page[BB_MARKER_OFFSET] page[BB_MARKER_OFFSET] = tmpStripping the metadata and ECCThe last step is to strip the unneeded metadata and ECC information to retrieve the 2048 byte of user data stored in the page:def strip_meta_and_ecc(src: bytes | bytearray) -&amp;gt; bytearray: if len(src) != PAGE_LEN: raise ValueError( f&quot;Supplied page data does not have required length: {PAGE_LEN}&quot; ) src_wo_meta = src[META_LEN:] dst = bytearray(USER_PAGE_LEN) for blk_idx in range(4): src_start = blk_idx * (BLOCK_LEN + ECC_LEN) data_block = src_wo_meta[src_start : src_start + BLOCK_LEN] dst_start = blk_idx * BLOCK_LEN dst[dst_start : dst_start + BLOCK_LEN] = data_block return dstConclusionWith the code snippets above, I was able to fully recover the data and correct any bit errors. I was even able to decompress the compressed portion of the stored data without any issues.It was very interesting to see and understand how the data is physically stored and protected in a NAND flash chip. I hope this information can be helpful to others that must go through the same process. Although NXP partially documents its implementation in the reference manual, there is no public implementation of the algorithm. And since all the mechanisms mentioned here are solely applied in hardware, there is no easy way to reverse engineer the implementation." }, { "title": "PCAN Device ID Support in Linux Kernel", "url": "/posts/Device-ID-support-in-Linux/", "categories": "Linux", "tags": "PEAK, PCAN, CAN, udev", "date": "2023-08-14 12:08:00 +0200", "snippet": "When building a test setup with multiple CAN controllers, it is crucial to ensure persistent device names, no matter boot or enumeration order. The PCAN USB-FD devices by Peak do not export a USB serial number, making it difficult to write udev rules to match against them. Instead, the controllers provide a concept called a Device ID. This ID is a 32 bit integer that is stored in the device’s flash memory and can be freely set by the user. Notably, a unique ID can be set for each CAN controller, i.e. the ID is not really a device ID but rather a controller ID for devices with multiple controllers. Starting with Linux version 6.3, the kernel now has support for reading &amp;amp; writing the device ID. Additionally, it can be used as a udev match attribute.Read &amp;amp; Write SupportThe Device ID is called CAN Channel ID in the kernel to reduce the disambiguity mentioned above. It can be read and written with ethtool. The byte order is always little endian.ReadingGiven a PCAN device as can0:ethtool -e can0WritingGiven a PCAN device as can0:echo &quot;00 11 22 33&quot; | xxd -r -p | ethtool -E can0udev SupportThe kernel exports a custom udev attribute for PCAN CAN controllers:ls -l /sys/class/net/can0/peak_usb/can_channel_idThe file exports the Device ID attribute as a hex-encoded, little-endian 32 bit integer. The value is read-only, i.e. it can only be set via ethtool. A rule can be written as follows:SUBSYSTEM==&quot;net&quot;, ACTION==&quot;add&quot;, KERNEL==&quot;can*&quot;, ATTR{peak_usb/can_channel_id}==&quot;00112233&quot;, NAME=&quot;mycan&quot;" }, { "title": "Determining ARM firmware base addresses", "url": "/posts/finding-arm-firmware-base-with-literal-pools/", "categories": "firmware", "tags": "ARM, firmware, reversing, literal pool", "date": "2022-04-15 20:08:00 +0200", "snippet": "A common problem when reversing a firmware blob is to determine the correct offset at which to place the firmware file in memory. Recently, while doing some research into possible solutions, I came across a paper by Zhu et al. The paper proposes an approach that exploits the addresses found in 32bit ARM literal pools to determine the correct firmware offset. I was able to successfully implement and use their approach to determine the offset of two firmware blobs. In this post, I present my implementation: First, I give a quick overview of ARM literal pools. I explain the algorithm concept and provide a detailed analysis of my implementation.ARM Literal PoolsInstructions in 32bit ARM can have a length of two or four bytes. This design choice poses some restrictions on how an address can be loaded into a register since a full 32bit address is too long to fit into a single instruction. The following code snippet provides an example of such a scenario:char foo(char *arr) { return arr[0];}int _start() { char a = foo(&quot;Bar Baz Buzz\\n&quot;); char b = foo(&quot;Bar Baz Buzz 22\\n&quot;); return a &amp;amp; b;}In order to call function foo, the compiler must place the address to the string literals in register r0. Since the strings are stored in the .rodata section of the application, they are potentially located out of range for PC-relative addressing. Hence, the compiler generates the following code:00008028 &amp;lt;_start&amp;gt;: ... 8034: e59f0038 ldr r0, [pc, #56] ; 8074 &amp;lt;_start+0x4c&amp;gt; 8038: ebfffff0 bl 8000 &amp;lt;foo&amp;gt; 803c: e1a03000 mov r3, r0 8040: e54b3005 strb r3, [fp, #-5] 8044: e59f002c ldr r0, [pc, #44] ; 8078 &amp;lt;_start+0x50&amp;gt; 8048: ebffffec bl 8000 &amp;lt;foo&amp;gt; ... 8074: 0000807c .word 0x0000807c 8078: 0000808c .word 0x0000808cIt places the absolute addresses to the two string literals at the end of the function and uses a PC-relative load instruction to fetch the values from the function trailer into register r0 before calling foo. A collection of such addresses at the end of a function is called a literal pool. For functions that access various different objects in the .data or .rodata sections, these pools can grow to a significant size. They need not only point to strings, the compiler also generates entries for other things like long program jumps, global variables or even C++ vtables.Since these literal pools use absolute addresses, they can potentially disclose or narrow down the base address of the firmware blob. In the following section, I describe how this can be accomplished by identifying and linking pool addresses to string literals.Algorithm ConceptFor our scenario, we assume to have been given a binary firmware blob that runs on a 32bit ARM chip and operates on string literals, meaning that it accesses string constants in the .rodata section. We don’t know at which address the firmware is loaded into memory. This makes firmware analysis more complicated because code jumps, variables or strings that rely on absolute addressing cannot be resolved if the firmware is placed at an incorrect location. Hence, the goal of this algorithm is to determine the absolute address at which the firmware image is supposed to be loaded into memory.PrerequisitesThe algorithm has two prerequisites that must be extracted from the firmware image beforehand: The offsets to all string literals that can be identified in the firmware image The addresses contained in all identifyable literal poolsAlthough I list these steps as prerequisite, identifying the literal pool addresses can be considered an important step in the algorithm. The results of these two steps do not necessarily need to be perfect, i.e. can contain false positives, as long as the amount of identified literal pools and string constants is sufficiently high.Algorithm DescriptionSince the compiler always creates literal pools for code that accesses string constants, we can assume that some of the literal pool addresses we identified in the last step must point to the string literals that we found. We can now try out different base addresses and determine the number of literal pool addresses that correctly link up with the identified string constants. The base address that maximizes this function can be considered the correct base address (given that we have correctly selected our candidate base addresses).This algorithm turns our search into an optimization problem. The advantage of this is that we do not need to find all strings or all literal pools. As long as we find a sufficient number of samples, we can be sure that our algorithm will converge. However, it can also be considered somewhat of a brute-force method, and we need to be smart about what addresses we consider as possible load locations for the firmware. If we select an address range that is too broad, the algorithm will likely not terminate. Fortunately, the non-volatile memory of most embedded chips is rather small compared to the 32 bit address space. Additionally, we can assume the firmware addresses to be aligned to 0x4 or possibly even 0x10 boundaries to further narrow down the search space.Algorithm ImplementationGiven the theoretical description in the previous section, simply put, we need to do three things: Identify the string constants in the firmware image, Identify ARM literal pools in the firmeware image, Try out all possible base addresses to determine the one that maximizes the matches between literal pool addresses and string locations.I implemented each step as part of a Python script. I published the full script as a GitHub Gist here. Below, I describe each step in greater detail.String SearchI used the following function to find strings in the firmware. It does a simple regular expression search to determine string literals locations in the image.def find_string_positions(data: bytes, align: int = None) -&amp;gt; List[int]: &quot;&quot;&quot;Find ASCII strings in the firmware blob and return the addresses The function uses a regular expression to find the addresses of valid ASCII strings in the firmware. If you set the align parameter to something other than None, make sure that the firmware blob is aligned to the same value. :param data: The firmware blob to search :param align: If set to a value other than None, all returned addresses are aligned to this value. :return: The addresses of valid strings in the firmware blob &quot;&quot;&quot; re_str = br&#39;[\\w\\s\\/*:,;$%&amp;amp;_-]{5,1000}&#39; regex = re.compile(re_str) str_pos = [m.start() for m in regex.finditer(data)] if align is not None: str_pos = [p for p in str_pos if p % align == 0] return str_posThe function operates directly on the firmware blob and outputs all locations, i.e. offsets relative to the beginning of the file, that match the regular expression. The regular expression matches against all strings that consist of alphanumeric characters, spaces, and the list of special characters. This is not necessarily a very precise or exhaustive definition but appears to be sufficient for at least some cases. In order to avoid false positives, the function can optionally filter out all addresses that are not aligned on a four-byte boundary. Since the firmware runs on a 32bit ARM chip, we can assume all strings placed in the .rodata section by the compiler will have this alignment.Literal Pool SearchThe second step is to locate literal pools in the firmware image. This step is based on the publication mentioned above but uses a simpler heuristic to accept or reject literal pool candidates. The search operates directly on the binary file and does not require any prior analysis to detect code blocks.The search assumes that a literal pool consists of multiple entries. All entries in such a pool must point to a certain region in address space. This is a valid assumption to make since we know the chip and its address mapping. If the firmware is loaded directly from the memory-mapped internal or external flash of the chip, the literal pools must point there. And since the size of most flash banks is rather limited, the valid address range is likely rather small. Consequently, we can assume a candidate pool to be valid if all addresses contained in it point to our target memory region.The algorithm uses a dynamically-sized window that is moved across the entire firmware image. With every iteration, the algorithm checks if all values inside the window can be interpreted as absolute addresses pointing into a certain address range. If that is the case, the region is assumed to be a literal pool and the window size is increased until the check fails. All addresses are then added to a buffer, and the window is reset and moved to the next position. Below, I list the complete function:def find_address_pools(data: bytes, target_range: Tuple[int, int], win_size: int = WIN_SIZE) -&amp;gt; List[int]: &quot;&quot;&quot;Find ARM 32 bit address pools in the firmware and return the contained addresses The function will only perform well if the target_range is narrow. Otherwise a lot of pools will be found. Also, the firmware blob must be word-aligned. :param data: The firmware blob to search for address pools :param target_range: The target address range that the addresses must point to. :param win_size: The minimum size that a pool must have :return: A list of unique addresses that were found in the pools &quot;&quot;&quot; data_arr = np.frombuffer(data, dtype=np.uint32) pos = 0 pool_size = win_size candidates = set() while (pos + pool_size) &amp;lt;= len(data_arr): pool = data_arr[pos:pos + pool_size] elements_in_range = np.logical_and(pool &amp;gt;= target_range[0], pool &amp;lt; target_range[1]) if not np.all(elements_in_range): if pool_size &amp;gt; win_size: # The last entry is not valid but we increased the pool size in the last iteration. # That means that the last iteration contained a valid pool. # Store the pool and reset the window pos += pool_size - 1 candidates.update(pool[:-1]) else: # Entries are not valid and we did not increase the window size in the last iteration # Move the window pos += 1 # Reset the pool size to default pool_size = win_size else: # All items are valid, increase the pool size pool_size += 1 return list(candidates)The algorithm accepts the firmware image as binary blob, a target address range, and the minimum window size (which defaults to 3). The target address range parameter represents the range in address space that the values in a candidate literal pool must point to in order to be considered valid. In general, this will be the address range of the flash memory.The algorithm first converts the binary firmware image into a numpy array of type uint32 with little endianess. Since all addresses inside a pool will be located on a 32 bit boundary, we can safely perform this conversion. The loop begins by placing the moving window at the beginning of the image. I then checks if all values inside the window are valid pool addresses, i.e. point into the target memory region. If that is the case, the window size is increased until the condition fails. All addresses in the pool are added to the result set and the window is reset to its minimum size and moved to the next position. This process is repeated until the window reaches the end of the image. The algorithm then returns a unique set of literal pool addresses as list.Load Address SearchThe last step is an exhaustive search over all possible firmware base addresses to determine the base address that maximizes the number of matches between literal pool addresses and string locations. Again, we must carefully consider the number of possible base addresses to not overwhelm the algorithm. If we select an address region that is too broad, the algorithm will not terminate. However, normally the range of valid base addresses is limited by the size of the ROM or RAM of the chip. Additionally, we can safely assume that the base address must at least align to a 4 byte boundary. Below, I show the code that performs the search.def count_matches_for_offsets(pool_addresses: np.ndarray, str_offsets: np.ndarray, candidate_load_addresses: List[int]) -&amp;gt; np.ndarray: &quot;&quot;&quot;For each offset in the search range, count how many str_offsets match up with the addr_pointers This function correlates the offsets of the strings that were found in the firmware to the target address pools. For each possible offset in offset_search_range, it calculates how many of the pool_addresses match up with the str_offsets + offset_search_range[i]. :param pool_addresses: The addresses that are supposed to point to the strings found in the firmware :param str_offsets: The offsets of all strings found in the firmware, relative to the start of the file :param candidate_load_addresses: The range of possible firmware offsets to try :return: For each offset in fw_offset_range, the function returns the number of pool_addresses that match up with the corresponding adjusted str_offsets. &quot;&quot;&quot; matches_lst = [] for i in tqdm(candidate_load_addresses, total=len(candidate_load_addresses)): cur_target_offsets = str_offsets + i intersect = np.intersect1d(pool_addresses, cur_target_offsets, assume_unique=True) matches_lst.append([i, len(intersect)]) return np.array(matches_lst, dtype=np.uint64)The function is given the list of literal pool addresses and string offsets determined previously. Both are provided as numpy arrays for easier handling. Third, the function requires the list of firmware base addresses for which to calculate the number of matches.For every possible base address, the function calculates the intersection of literal pool addresses and absolute string offsets. The intersection is equivalent to the number of address pool entries that correctly match up with a string. The function returns an 2D array that list for each load offset the number matched strings.Putting it all togetherLastly, I use the following code snippet with main function to put it all together. The window size is set to 3 and the word size is set to 4. The chip had an internal flash with an address range from 0x0 to 0x80000. Hence, I configured the target range to fall within that part of address space. Lastly, I set a step size of 0x10. This is an important hyperparameter, as it can lead to false results if set too big or cause the algorithm not to finish in time if set too small. In general, it shouldn’t need to be set to a value smaller than the word size of the system.The main function itself chains together the functions explained above. It collects the string offsets and literal pool addresses. It converts the results into numpy arrays for easier handling. After calculating the match array, it determines the base address with the maximum number of matches and generates a plot for visualization.WIN_SIZE = 3WORD_SIZE = 4TARGET_RANGE = (0x0, 0x80000)STEP_SIZE = 0x10def main(): fpath = sys.argv[1] with open(fpath, &#39;rb&#39;) as f: firmware = f.read() time_pre = time.time() str_pos = find_string_positions(firmware, align=WORD_SIZE) print(f&quot;Found {len(str_pos)} unique strings&quot;) pool_addresses = find_address_pools(firmware, target_range=TARGET_RANGE, win_size=WIN_SIZE) print(f&quot;Found {len(pool_addresses)} unique pool addresses&quot;) str_pos_arr = np.array(str_pos) pool_addresses_arr = np.array(pool_addresses) search_range = range(TARGET_RANGE[0], TARGET_RANGE[1], STEP_SIZE) matches = count_matches_for_offsets(pool_addresses_arr, str_pos_arr, list(search_range)) time_post = time.time() runtime = time_post - time_pre print(f&quot;Total runtime: {runtime:.2f}s&quot;) max_index = np.argmax(matches[:, 1]) max_offset, n_matches = matches[max_index] print(f&quot;Offset for max alignment: {max_offset:08x}&quot;) print(f&quot;Total matches: {n_matches}&quot;) sns.set_theme() plt.plot(matches[:, 0], matches[:, 1]) plt.xlim(*TARGET_RANGE) plt.xlabel(&#39;Offset&#39;) plt.ylabel(&#39;Aligned strings&#39;) plt.savefig(&#39;plot.png&#39;, dpi=300) plt.show()Base Address DiscoveryWhen I ran the script with specified hyperparameters against my firmware blob, the code generated the following output:Found 497 unique stringsFound 1455 unique pool addresses100%|██████████| 32767/32767 [00:01&amp;lt;00:00, 18749.79it/s]Total runtime: 2.26sOffset for max alignment: 00004fe0Total matches: 317The search took a little over two seconds. The script found 497 unique strings and 1455 unique pool addresses. Using a base address of 0x4fe0, the script was able to match 317 of the strings to corresponding literal pool addresses. However, this information alone does not convey any information about the significance of the maximum that it determined. To give a visual impression of the significance, I show the generated graph below:The figure shows a singular peak at offset 0x4fe0. The peak is very pronounced and represents a significant outlier in comparison to the remaining samples. Hence, it is safe to assume that this value represents the likely load address of the binary.To give further weight to the result, I compared the auto analysis results of Ghidra for the default load address 0x0 and the result 0x4fe0. The figure below shows the (rotated) Overview sidebar in Ghidra for both analysis attempts. The width of the bar represents the length of the firmware image. The colors encode what data the analysis discovered in the firmware image. Purple indicates code, green indicates data, and red indicates unknown sections.The figure shows quite nicely that the second iteration of the analysis with the discovered base address of 0x4fe0 lead to a significantly better result. Ghidra was able to discover more instructions across the entire firmware image and more accurately link references to the data section of the image.Given the collective results above, 0x4fe0 appears to be the correct base address for the firmware image.Hyperparameter TuningLastly, I wanted to check how the selection of the step size would affect the accuracy of the result. Below, I list the result for multiple iterations with varyiing step sizes: Step Size Runtime Matches Base Address 0x1 28.80s 317 0x4fe0 0x4 7.47s 317 0x4fe0 0x10 2.26s 317 0x4fe0 0x40 1.48s 89 0x5000 0x2000 0.70s 36 0x4000 In our case, decreasing the steps size did not yield any improvement, further demonstrating the correctness of the result. However, increasing the step size past a value of 0x10 caused the algorithm to miss the absolute maximum. Nevertheless, the determined maximum remained as close to the actual maximum as possible. This would indicate that it is possible to safe computation time in large searches by iteratively decreasing the target address range along with the step size.ConclusionBy using the method proposed in the paper by Zhu et al., I was able to correctly determine the base address of the firmware image I was dealing with. Furthermore, I hope that the code I posted here (and in the GitHub Gist) can be of use to someone else." }, { "title": "Debugging Linux Module Loading with QEMU", "url": "/posts/compiling-intree-linux-modules/", "categories": "Linux, Kernel", "tags": "Linux, Kernel, QEMU, Debugging", "date": "2021-12-11 18:21:11 +0100", "snippet": "My company uses the ETAS ES582.1 CAN adapters to interface with a CAN bus. Since recently, the kernel has mainline support for these devices (the etas_es58x driver). However, my work operating system of choice, Kali Linux, does not ship with a prebuilt kernel module for the devices out of the box. Hence, I needed to manually compile the module to use the devices under Kali. While doing so, I ran into binary compatibility issues and ended up debugging the module loading process with QEMU to determine the root cause. This blog post is a summary of the process. I first explain the QEMU VM installation process, explain the issues I encountered, and outline the debugging process to pinpoint the issue. Spoiler: If you arrived at this post in hopes of fixing the error message below, try installing the pahole tool. On Kali, the required package is called dwarves. If that doesn’t work, I invite you to follow this post and try debugging for yourself.On the host, I used an Arch Linux installation. The QEMU VM ran the target operating system, a Kali Linux installation. All my attempts were made on Kernel version 5.14.16.QEMU VM SetupOn Arch, I merely needed to install the qemu package to get started. I then set up the VM image and started the installation. For the image, I intentionally used the raw format because it can easily be mounted on the host side as a loop device for manipulation. Additionally, for filesystems like ext4 that support holes, only non-zero blocks in the file will take up disk space. I created a rather big image to accommodate the source code and debug package. The second command starts up the VM with KVM, 4GB of memory and inserts the Kali installation disk.$ qemu-img create -f raw kali_hd2.raw 16G$ qemu-system-x86_64 -boot order=d -drive file=kali_hd.raw,format=raw -m 4G -enable-kvm -cdrom kali-linux-2021.3a-installer-netinst-amd64.isoI installed a minimal Kali version without desktop environment and no preinstalled pentesting tools to reduce the size. Next, I ran the VM without ISO and with enabled gdb stub for attaching the debugger later on:$ qemu-system-x86_64 -boot order=d -drive file=kali_hd.raw,format=raw -m 4G -enable-kvm -sKernel Module CompilationThe next step was to actually compile the module inside the VM. I used the linux-source package for maximum compatibility with the prebuilt kernel. apt automatically pulled in Kali package version 5.14.16-1kali1.$ sudo apt-get install build-essential libncurses5-dev libelf-dev libssl-dev$ sudo apt-get install linux-source linux-headers-amd64$ tar -xf /usr/src/linux-source-5.14.tar.xz$ cd linux-source-5.14/Next, I prepared the sources for compilation. I copied the configuration file and module symbol version file from the linux-headers package.$ cp /usr/src/linux-headers-5.14.0-kali4-amd64/.config .$ cp /usr/src/linux-headers-5.14.0-kali4-amd64/Module.symvers .Since the module I wanted to compile was not enabled in the .config file, I manually enabled the module by adding the following line to the file:CONFIG_CAN_ETAS_ES58X=mFinally, I was able to compile the module. The first step in the series of commands checks the configuration file for completeness and queries the user for any missing configuration option. I stuck with the defaults.$ make oldconfig$ make prepare$ make modules_prepare$ make M=drivers/net/can/usb/etas_es58x/Next I tried to insmod the new module and its dependencies for a quick test:$ for i in can-dev usbcore crc16; do sudo modprobe $i; done$ sudo insmod drivers/net/can/usb/etas_es58x/etas_es58x.koinsmod: ERROR: could not insert module drivers/net/can/usb/etas_es58x/etas_es58x.ko: Invalid module formatAs expected, the module insertion failed due to some unknown issue with the module. Next, I checked the kernel log:$ sudo dmesg | tail -n 1[ 2056.862808] module: x86/modules: Skipping invalid relocation target, existing value is nonzero for type 1, loc 00000000909cc68f, val ffffffffc087f984The debug message was rather cryptic, but revealed that there seemed to be some issue with the symbol relocation during module linking. I dug up the kernel code responsible for loading the modules and took a closer look at the loading process.Static analysis of the module loading processFrom the debug message, I was able to trace the location in the code where the linking process failed. The message was printed from inside __apply_relocate_add in arch/x86/kernel/module.c. The function is responsible for applying relocations to ELF sections of the module.A short excursion on relocationsIn generic terms, a relocation links the reference of a symbol to its definition. As an example, if a kernel module wants to call a function like printk, which it does not provide itself, it must know the address at which the function is located. Since the address is not known at compile time, it must be dynamically inserted into the module at load time. The process of performing this search and replace is defined by a relocation.The relocations that need to be applied to the kernel module at startup are stored in the ELF file along with code and data. For each section to which relocations must be applied, the module contains a .rela section with relocations. As an example, most modules feature a .text section that contains the compiled code of the module. The relocations for that section are stored in the .rela.text section.Each relocation in a .rela section consists of several values: The location relative to the start of the target section at which the relocation must be applied. A link to the symbol that must be inserted at the specified location. The type of the relocation. Relocation types are specific to a processor and define how the symbol value must be inserted at the location. An addend, however this is not strictly relevant to this postTo give a quick example, below I list a relocation from the .rela.text section in the etas_es58x module: Offset Info Type Sym. Value Sym. Name + Addend000000000031 00c900000004 R_X86_64_PLT32 0000000000000000 memcpy - 4The relocation specifies that the address of symbol memcpy must be placed at offset 0x31 relative to the beginning of the .text section.Analysis of the relocation errorBelow is the source code of __apply_relocate_add (arch/x86/kernel/module.c). The function applies all relocations contained in a single .rela section. For each relocation, it calculates the absolute address of the relocation in loc and the symbol value in val. The switch case statement that follows is responsible for applying the symbol value according to the relocation type. The function also performs a sanity check before it applies a relocation: it checks if the location in memory is properly initialized to zero. If not, it aborts with an error message.static int __apply_relocate_add(Elf64_Shdr *sechdrs, const char *strtab, unsigned int symindex, unsigned int relsec, struct module *me, void *(*write)(void *dest, const void *src, size_t len)){ unsigned int i; Elf64_Rela *rel = (void *)sechdrs[relsec].sh_addr; Elf64_Sym *sym; void *loc; u64 val; DEBUGP(&quot;Applying relocate section %u to %u\\n&quot;, relsec, sechdrs[relsec].sh_info); for (i = 0; i &amp;lt; sechdrs[relsec].sh_size / sizeof(*rel); i++) { /* This is where to make the change */ loc = (void *)sechdrs[sechdrs[relsec].sh_info].sh_addr + rel[i].r_offset; /* This is the symbol it is referring to. Note that all undefined symbols have been resolved. */ sym = (Elf64_Sym *)sechdrs[symindex].sh_addr + ELF64_R_SYM(rel[i].r_info); DEBUGP(&quot;type %d st_value %Lx r_addend %Lx loc %Lx\\n&quot;, (int)ELF64_R_TYPE(rel[i].r_info), sym-&amp;gt;st_value, rel[i].r_addend, (u64)loc); val = sym-&amp;gt;st_value + rel[i].r_addend; switch (ELF64_R_TYPE(rel[i].r_info)) { case R_X86_64_NONE: break; case R_X86_64_64: if (*(u64 *)loc != 0) goto invalid_relocation; write(loc, &amp;amp;val, 8); break; case R_X86_64_32: if (*(u32 *)loc != 0) goto invalid_relocation; write(loc, &amp;amp;val, 4); if (val != *(u32 *)loc) goto overflow; break; case R_X86_64_32S: if (*(s32 *)loc != 0) goto invalid_relocation; write(loc, &amp;amp;val, 4); if ((s64)val != *(s32 *)loc) goto overflow; break; case R_X86_64_PC32: case R_X86_64_PLT32: if (*(u32 *)loc != 0) goto invalid_relocation; val -= (u64)loc; write(loc, &amp;amp;val, 4);#if 0 if ((s64)val != *(s32 *)loc) goto overflow;#endif break; case R_X86_64_PC64: if (*(u64 *)loc != 0) goto invalid_relocation; val -= (u64)loc; write(loc, &amp;amp;val, 8); break; default: pr_err(&quot;%s: Unknown rela relocation: %llu\\n&quot;, me-&amp;gt;name, ELF64_R_TYPE(rel[i].r_info)); return -ENOEXEC; } } return 0;invalid_relocation: pr_err(&quot;x86/modules: Skipping invalid relocation target, existing value is nonzero for type %d, loc %p, val %Lx\\n&quot;, (int)ELF64_R_TYPE(rel[i].r_info), loc, val); return -ENOEXEC;overflow: pr_err(&quot;overflow in relocation type %d val %Lx\\n&quot;, (int)ELF64_R_TYPE(rel[i].r_info), val); pr_err(&quot;`%s&#39; likely not compiled with -mcmodel=kernel\\n&quot;, me-&amp;gt;name); return -ENOEXEC;}This error message is the same as the one that was displayed when I tried to load my freshly-compiled module. Apparently, the dynamic linker encountered a relocation where the target address already held a non-zero value. However, a quick check with readelf -a etas_es58x.ko revealed that none of the relocation targets in the respective sections of the ELF file held a non-zero value. Consequently, the location had to have been manipulated at runtime while the module was being loaded. Unfortunately, the error message itself did not yield any useful information, like the section in which the issue occurred or the name of the affected symbol. Hence, I decided to investigate the issue further by debugging the function at runtime using QEMU.Dynamic analysis with QEMU and GDBIn order to debug the kernel, I needed to set up gdb, acquire an ELF file of the compiled kernel that contained debug symbols, and disable KASLR, the kernel address space layout randomization.SetupI normally run gdb with gef which provides a convenient context print during debugging as well as some advanced features for memory inspection.Kali has a convenient package called linux-image-amd64-dbg. It contains an ELF file of the kernel with debugging symbols. However, for the debugging I needed both the source code as well as the ELF file on the host to connect to the gdb server stub of QEMU. Fortunately, with the raw image format, it was very easy to mount and copy data from the image:$ sudo losetup -f kali_hd.raw$ sudo partprobe /dev/loop0$ sudo mount /dev/loop0p1 /mnt$ cp -r /mnt/home/kali/linux-source-5.14/ .$ cd linux-source-5.14/$ cp /mnt/usr/lib/debug/boot/vmlinux-5.14.0-kali4-amd64 .$ sudo umount /mnt$ sudo losetup -DI also loaded the ELF file of the kernel image into Ghidra for analysis. This allowed me to look around and do cross-referencing more easily than I was able to do from inside gdb.Lastly, I needed to disable the kernel address space layout randomization. This can be done by booting the kernel with the keyword nokaslr. I edited /etc/default/grub in the VM and added nokaslr to the following line in the file:GRUB_CMDLINE_LINUX=&quot;nokaslr&quot;Then I recreated the grub configuration file:$ sudo update-grubBreaking at the failing functionI started the VM with the -s flag to start a gdb server on localhost:1234. Then I ran gdb and connected to the server:$ gdb ./vmlinux-5.14.0-kali4-amd64My plan was to pinpoint the relocation section and symbol that were causing the error condition by breaking at the error handler. However, due to compiler optimizations, most stack-based variable storage had been optimized away. The index of the relocation section relsec was passed into the function in the $ecx register but dropped after the absolute address of the section header had been calculated. Hence, I added two breakpoints in __apply_relocate_add. I added one breakpoint at the function start and another breakpoint at the error handler (the exact address of which I was able to determine with Ghidra). This setup allowed me to break at the function prologue to intercept the call parameters. If the second breakpoint hit right afterwards I knew that the last seen section was the offending one.target remote localhost:1234break apply_relocate_addbreak *(apply_relocate_add+0x85a08c)continueThe offending module relocationI loaded the module inside the VM to trigger the breakpoint. At iteration relsec == 0x23, the second breakpoint hit, meaning that the error occurred there. The relocation section with index 0x23 was .rela.gnu.linkonce.this_module. The section contains the module struct with information (such as the name) about the module. The struct is kept in memory by the kernel and filled with runtime information. The relocation section for it featured two entries: Offset Info Type Sym. Value Sym. Name + Addend000000000138 00d400000001 R_X86_64_64 0000000000000000 init_module + 0000000000340 00c800000001 R_X86_64_64 0000000000000000 cleanup_module + 0The relocations tell the kernel to place the address of the init_module and the cleanup_module function at the specified offsets in the struct. One of the two relocations failed, however I didn’t yet know which one of the two. Fortunately, according to the decompiled source and assembly from Ghidra, the counter variable i in __apply_relocate_add had been placed in register r13 by the compiler, and the register was not written to for any other purpuses except the counter. This allowed me to simply dump the contents with p $r13 when the debugger hit the second breakpoint. The issue was with the second relocation for cleanup_module at index i == 1.Tracing struct module write accessesThe next thing I wanted to try out was to determine what data was being written to the location. Since the offset was initialized to zero in the ELF file, it must have been written to directly before the relocation. I noticed that the module struct was first accessed quite early in the module loading process in setup_load_info of module.c:static int setup_load_info(struct load_info *info, int flags){ ... info-&amp;gt;index.mod = find_sec(info, &quot;.gnu.linkonce.this_module&quot;); if (!info-&amp;gt;index.mod) { pr_warn(&quot;%s: No module found in object\\n&quot;, info-&amp;gt;name ?: &quot;(missing .modinfo section or name field)&quot;); return -ENOEXEC; } /* This is temporary: point mod into copy of data. */ info-&amp;gt;mod = (void *)info-&amp;gt;hdr + info-&amp;gt;sechdrs[info-&amp;gt;index.mod].sh_offset; ...}In the last line, info-&amp;gt;mod is set to point to the location of the gnu.linkonce.this_module section. Successive access to the struct always uses the reference stored in info. As the comment explains, the address is only temporary since the module still has to be copied to its final location.In order to determine the address of section gnu.linkonce.this_module and hence the address of the module struct, I set a breakpoint in load_module because setup_load_info had been optimized away.b *(load_module + 0x32d)Once the breakpoint hit, I set a custom watch point to break whenever the pointer to the cleanup_module function was being manipulated:$ p $r13$5 = 0xffffc90002e52c80$ awatch *(0xffffc90002e52c80 + 0x340)Hardware access (read/write) watchpoint 2: *(0xffffc90002e52c80 + 0x340)$ continueThe first time the breakpoint hit was in memcpy when the entire section was being copied to its final location in kernel memory. I added a new watchpoint to the same section offset in target memory. The new breakpoint hit in load_module+0x1025, which Ghidra presented as the following decompiled C code: *(int **)(piVar37 + 0xce) = piVar37 + 0xcc; *(int **)(piVar37 + 0xcc) = piVar37 + 0xcc; *(int **)(piVar37 + 0xd0) = piVar37 + 0xd0; *(int **)(piVar37 + 0xd2) = piVar37 + 0xd0; LOCK(); piVar37[0xd6] = piVar37[0xd6] + 1; __mutex_init(piVar37 + 0x3a,s_&amp;amp;mod-&amp;gt;param_lock_ffffffff8210fe43, &amp;amp;__key.7); uVar11 = find_sec(info,s___param_ffffffff8210fe54);The code writes some unknown data to the pointer of cleanup_module. Directly afterwards, it initializes a mutex and calls the find_sec function to determine the index of the __param section. There was only one location in the module loading code where this disassembly could have originated from - somewhat in the middle of the load_module code: /* To avoid stressing percpu allocator, do this once we&#39;re unique. */ err = percpu_modalloc(mod, info); if (err) goto unlink_mod; /* Now module is in final location, initialize linked lists, etc. */ err = module_unload_init(mod); if (err) goto unlink_mod; init_param_lock(mod); /* * Now we&#39;ve got everything in the final locations, we can * find optional sections. */ err = find_module_sections(mod, info); if (err) goto free_unload;The mutex is initialized in init_param_lock and find_sec(&quot;__param&quot;) is executed in find_module_sections. Hence, the modification of the cleanup_module pointer had to occur in the module_unload_init function. And indeed, the function initialized two linked lists in struct module:/* Init the unload section of the module. */static int module_unload_init(struct module *mod){ /* * Initialize reference counter to MODULE_REF_BASE. * refcnt == 0 means module is going. */ atomic_set(&amp;amp;mod-&amp;gt;refcnt, MODULE_REF_BASE); INIT_LIST_HEAD(&amp;amp;mod-&amp;gt;source_list); INIT_LIST_HEAD(&amp;amp;mod-&amp;gt;target_list); /* Hold reference count during initialization. */ atomic_inc(&amp;amp;mod-&amp;gt;refcnt); return 0;}In assembly, the initialization operation is even more clearly visible. fff811405d7 LEA RAX,[R13 + 0x330] fff811405de MOV dword ptr [R13 + 0x358],0x1 fff811405e9 MOV qword ptr [R13 + 0x338],RAX fff811405f0 MOV qword ptr [R13 + 0x330],RAX fff811405f7 LEA RAX,[R13 + 0x340] fff811405fe MOV qword ptr [R13 + 0x340],RAX fff81140605 MOV qword ptr [R13 + 0x348],RAXRegister $r13 contained the address of the module struct. The forward and backward pointers in each list were initialized to loop back to the list instance. Interestingly, the second of the two lists was clearly leaking into the cleanup_module pointer, which the relocation operation expected to be located at offset 0x340 of the struct. In the struct definition, the two linked lists were directly bordering on the cleanup_module function pointer, here called exit:struct module {// ...#ifdef CONFIG_MODULE_UNLOAD /* What modules depend on me? */ struct list_head source_list; /* What modules do I depend on? */ struct list_head target_list; /* Destruction function. */ void (*exit)(void); atomic_t refcnt;#endif// ...}To summarize the finding, the kernel module loading code and the relocations in the module were using two different, binary incompatible definitions of struct module. In the version known to the module, the exit function pointer had moved to the front of the struct by 16 Bytes.The root causeAlthough I had made an exact copy of the kernel configuration used by the Kali package maintainers, apparently some configuration options were manipulating the struct module definition and causing the offset. I made a diff of my local .config file and the one that shipped with the source package: CONFIG_DEBUG_KERNEL=y--- /usr/src/linux-headers-5.14.0-kali4-amd64/.config 2021-11-05 11:54:48.000000000 +0100+++ .config 2021-11-22 21:41:25.519431077 +0100@@ -2,9 +2,9 @@ # Automatically generated file; DO NOT EDIT. # Linux/x86 5.14.16 Kernel Configuration #-CONFIG_CC_VERSION_TEXT=&quot;gcc-10 (Debian 10.3.0-12) 10.3.0&quot;+CONFIG_CC_VERSION_TEXT=&quot;gcc (Debian 11.2.0-10) 11.2.0&quot; CONFIG_CC_IS_GCC=y-CONFIG_GCC_VERSION=100300+CONFIG_GCC_VERSION=110200 CONFIG_CLANG_VERSION=0 CONFIG_AS_IS_GNU=y CONFIG_AS_VERSION=23700@@ -14,6 +14,7 @@ CONFIG_CC_CAN_LINK=y CONFIG_CC_CAN_LINK_STATIC=y CONFIG_CC_HAS_ASM_GOTO=y+CONFIG_CC_HAS_ASM_GOTO_OUTPUT=y CONFIG_CC_HAS_ASM_INLINE=y CONFIG_CC_HAS_NO_PROFILE_FN_ATTR=y CONFIG_IRQ_WORK=y@@ -1893,7 +1894,7 @@ CONFIG_CAN_8DEV_USB=m CONFIG_CAN_EMS_USB=m CONFIG_CAN_ESD_USB2=m-# CONFIG_CAN_ETAS_ES58X is not set+CONFIG_CAN_ETAS_ES58X=m CONFIG_CAN_GS_USB=m CONFIG_CAN_KVASER_USB=m CONFIG_CAN_MCBA_USB=m@@ -9716,8 +9717,6 @@ CONFIG_DEBUG_INFO_DWARF_TOOLCHAIN_DEFAULT=y # CONFIG_DEBUG_INFO_DWARF4 is not set CONFIG_DEBUG_INFO_BTF=y-CONFIG_PAHOLE_HAS_SPLIT_BTF=y-CONFIG_DEBUG_INFO_BTF_MODULES=y # CONFIG_GDB_SCRIPTS is not set CONFIG_FRAME_WARN=2048 CONFIG_STRIP_ASM_SYMS=y@@ -9747,6 +9746,8 @@ CONFIG_ARCH_HAS_UBSAN_SANITIZE_ALL=y # CONFIG_UBSAN is not set CONFIG_HAVE_ARCH_KCSAN=y+CONFIG_HAVE_KCSAN_COMPILER=y+# CONFIG_KCSAN is not set # end of Generic Kernel Debugging Instruments CONFIG_DEBUG_KERNEL=yOf all configuration options that were different in both versions, option CONFIG_DEBUG_INFO_BTF_MODULES was the most interesting to my case. If enabled, it added two members to struct module:struct module {// ...#ifdef CONFIG_DEBUG_INFO_BTF_MODULES unsigned int btf_data_size; void *btf_data;#endif// ...}Given the alignment requirements of amd64, the compiler would likely add 4 Byte of padding between the int and the void pointer, resulting in a size of 16 Byte for the two members. At that point I was fairly certain I had found the culprit for my issues. The only thing I did not know was why the option had been disabled.I retraced my compilation steps to determine why the option was disabled. The option seemed to be magically turned off after executing make oldconfig. After digging a little in the documentation, I found the reason: I was missing the pahole tool in my PATH. The Makefile automatically disabled the option if pahole was not found.I installed the dwarves package in Kali, recompiled the kernel module, and called insmod to insert the module into the kernel. And behold:$ lsmod | grep etasetas_es58x 53248 0usbcore 331776 1 etas_es58xcan_dev 40960 1 etas_es58xcrc16 16384 2 etas_es58x,ext4The module was happy and alive.Takeaway MessageWhen compiling a kernel module: always make sure that the configuration file doesn’t change while you’re not looking. This scenario wasn’t something I was aware of until now. And frankly, I do not consider it to be good design. Of course I don’t have the entire picture, but I believe a missing dependency should cause a build to fail fast, not produce incompatible artifacts." } ]
